# -*- mode: ruby -*-
# vi: set ft=ruby


require "yaml"
require "fileutils"
load "dvmtools.rb"

IPS = {
  cs: "192.168.33.100",
  db: "192.168.33.150",
  be: "192.168.33.151",
  ldap: "192.168.33.152",
  custom: "192.168.33.153",
  reportingdb: "192.168.33.155",
  elasticsearch: "192.168.33.156",
  solr: "192.168.33.157"
}


# Just in case you have a hankering to start a VM to run components on the
# same network that don't fall into the categories above.
# Enable it by setting config.yml value `vm.custom` to `true`,
# then bring it up with `vagrant up custom`

DB_SUPERUSER="bofh"
DB_SUPERPASS="i1uvd3v0ps"
LDAP_PASSWORD='H0\/\/!|\/|3tY0ur|\/|0th3r'

nodes_dir = File.join(File.expand_path(File.dirname(__FILE__)), 'nodes')
if File.directory?(nodes_dir)
  # This prevents attributes from previous runs from getting
  # merged back into node attributes during provisioning.
  #
  # It prevents annoying things, like "private-chef-cookbooks never
  # stops loading from the current repo instead of the package" - because
  # the node attr that says to do that never got cleared.
  Dir.glob(File.join(nodes_dir, "*.json")).each do  |nodefile|
    File.delete(nodefile)
  end
else
  puts "nodes directory is missing...creating it now"
  FileUtils.mkdir(nodes_dir)
end

Vagrant.configure("2") do |config|
  attributes = load_settings

  # Use the official Ubuntu 14.04 box
  # Vagrant will auto resolve the url to download from Atlas
  config.vm.box = "bento/ubuntu-14.04"
  config.ssh.forward_agent = true

  # This plugin allows for a much more efficient sync than the vanilla rsync-auto command
  # see https://github.com/smerrill/vagrant-gatling-rsync
  if Vagrant.has_plugin?('vagrant-gatling-rsync')
    config.gatling.rsync_on_startup = false
  end

  if attributes['vm'].has_key? 'postgresql'
    if attributes['vm']['postgresql']['start']
      config.vm.define("database") do |c|
        define_db_server(c, attributes)
      end
    end
  else
    attributes['vm']['postgresql'] = nil
  end

  if attributes['vm'].has_key? 'reporting_postgresql'
    if attributes['vm']['reporting_postgresql']['start']
      config.vm.define("reportingdb") do |c|
        define_db_server_reporting(c, attributes)
      end
    end
  else
    attributes['vm']['reporting_postgresql'] = nil
  end

  if attributes['vm'].has_key? 'ldap'
    if attributes['vm']['ldap']['start']
      config.vm.define('ldap') do |c|
        define_ldap_server(c, attributes)
      end
    end
  end

  if attributes['vm'].has_key? 'chef-backend'
    if attributes['vm']['chef-backend']['start']
      config.vm.define("backend") do |c|
        define_backend_server(c, attributes)
      end
    end
  else
    attributes['vm']['chef-backend'] = nil
  end

  if attributes['vm'].has_key? 'elasticsearch'
    if attributes['vm']['elasticsearch']['start'] == true
      config.vm.define('elasticsearch') do |c|
        define_elasticsearch_server(c, attributes)
      end
    end
  else
    attributes['vm']['elasticsearch'] = nil
  end

  if attributes['vm'].has_key? 'external_solr'
    if attributes['vm']['external_solr']['start'] == true
      config.vm.define('external_solr') do |c|
        define_external_solr_server(c, attributes)
      end
    end
  else
    attributes['vm']['external_solr'] = nil
  end

  if attributes['vm']['start-custom'] == true
    config.vm.define("custom") do |c|
      define_custom_server(c, attributes)
    end
  end

  config.vm.define("chef-server", primary: true) do |c|
    define_chef_server(c, attributes)
  end
end


def define_chef_server(config, attributes)
  provisioning, installer, installer_path = prepare('INSTALLER', 'chef-server-core', 'Chef Server 12+')
  _m_provisioning, m_installer, _m_installer_path = prepare('MANAGE_PKG', 'chef-manage', 'Chef Manage 1.4+') if plugin_active?('chef-manage', attributes)
  _ps_provisioning, ps_installer, _ps_installer_path = prepare('PUSH_JOBS_PKG', 'opscode-push-jobs-server', 'Push Jobs Server 1.1+') if plugin_active?('push-jobs-server', attributes)
  _r_provisioning, r_installer, _r_installer_path = prepare('REPORTING_PKG', 'opscode-reporting', 'Chef Reporting 1.6+') if plugin_active?('reporting', attributes)

  config.vm.hostname = "api.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:cs]

  vmattr = attributes["vm"]
  customize_vm(config, memory: vmattr["memory"], cpus: vmattr["cpus"], name: "chef-server")
  if provisioning
    autoload = vmattr["omnibus-autoload"]
    show_autoload_banner(autoload)
    json = {
      "install_packages" => vmattr["packages"],
      "tz" => host_timezone,
      "omnibus-autoload" => vmattr["omnibus-autoload"],
      "provisioning" => { "hosts" => ips_to_fqdns }
    }.merge vmattr["node-attributes"]

    if vmattr["postgresql"]["start"] and vmattr["postgresql"]["use-external"]
      # TODO make this stuff common - we have these values in 2-3 places now...
      pg = { "postgresql['external']" => true,
             "postgresql['vip']" => "\"#{IPS[:database]}\"",
             "postgresql['port']" => 5432,
             "postgresql['db_superuser']" => "\"#{DB_SUPERUSER}\"",
             "postgresql['db_superuser_password']" => "\"#{DB_SUPERPASS}\"",
             "opscode_erchef['db_pool_size']" => 10,
             "oc_id['db_pool_size']" => 10,
             "oc_bifrost['db_pool_size']" => 10 }
      json = simple_deep_merge(json, { "provisioning" => { "chef-server-config" => pg } })
    end

    if vmattr["reporting_postgresql"]["start"] and vmattr["reporting_postgresql"]["use-external"]
      pg = { "postgresql['external']" => true,
             "postgresql['vip']" => "\"#{IPS[:reportingdb]}\"",
             "postgresql['port']" => 5432,
             "postgresql['db_superuser']" => "\"#{DB_SUPERUSER}\"",
             "postgresql['db_superuser_password']" => "\"#{DB_SUPERPASS}\""
      }
      json = simple_deep_merge(json, { "provisioning" => { "opscode-reporting-config" => pg } })
    end

    if vmattr['ldap']['start']
      backend_compat_message('ldap') if chef_backend_active?(attributes)
      ldap = { "ldap['base_dn']" => '"ou=chefs,dc=chef-server,dc=dev"',
               "ldap['bind_dn']" => '"cn=admin,dc=chef-server,dc=dev"',
               "ldap['bind_password']" => "'#{LDAP_PASSWORD}'",
               "ldap['host']" => "'#{IPS[:ldap]}'",
               "ldap['login_attribute']" => '"uid"'
      }
      json = simple_deep_merge(json, { "provisioning" => { "chef-server-config" => ldap } })
    end

    if vmattr['elasticsearch'] && vmattr['elasticsearch']['start']
      elasticsearch = { "opscode_solr4['external']" => "true",
                        "opscode_solr4['external_url']" => '"http://elasticsearch:9200"',
                        "opscode_erchef['search_provider']" => '"elasticsearch"',
                        "opscode_erchef['search_queue_mode']" => '"batch"',
                        "rabbitmq['enabled']" => "false",
                        "rabbitmq['management_enabled']" => "false",
                        "dark_launch['actions']" => "false"
      }
      json = simple_deep_merge(json, { "provisioning" => { "chef-server-config" => elasticsearch } })
    end

    if vmattr['external_solr'] && vmattr['external_solr']['start']
      external_solr = { "opscode_solr4['external']" => "true",
                        "opscode_solr4['external_url']" => '"http://solr.chef-server.dev:8983/solr"',
                        "opscode_erchef['search_provider']" => '"solr"',
                        "opscode_erchef['search_queue_mode']" => '"batch"'
      }
      json = simple_deep_merge(json, { "provisioning" => { "chef-server-config" => external_solr } })
    end

    dotfiles_path = vmattr["dotfile_path"] || "dotfiles"
    # This is only used for the initial sync  - it was prone failures when allowed
    # to run otherwise. Instead, run thet command './sync' in the dev dir after the vm is online.
    config.vm.synced_folder File.absolute_path(File.join(Dir.pwd, "../")), "/host",
      type: "rsync",
      rsync__args: ["--verbose", "--archive", "--delete", "-z", "--no-owner", "--no-group" ],
      rsync__exclude: vmattr['sync']['exclude-files']
    config.vm.synced_folder installer_path, "/installers"
    config.vm.synced_folder File.expand_path(dotfiles_path), "/dotfiles"

    # Preserve gitconfig from host
    config.vm.provision "file", source: "~/.gitconfig", destination: ".gitconfig"
    # Install the chef-server package now so that its chef client is available to us
    config.vm.provision "shell", inline: install_hack(installer, 'opscode')
    # Force the path we want for root - this may no longer be needed...
    config.vm.provision "shell", inline: 'echo "PATH=/opt/opscode/embedded/bin:$PATH" > /root/.bashrc'

    # Set up the chef-zero recipes to run
    recipes = %w{provisioning::hosts provisioning::chef-server
                 provisioning::chef-server-rb
                 dev::system dev::user-env dev::dvm}
    set_chef_zero_provisioning(config, recipes: recipes, binary_path: "/opt/opscode/embedded/bin", json: json)

    if chef_backend_active?(attributes)
      # Grab the chef-server.rb that chef-backend generates for us and overwrite the one we
      # made in provisioning
      config.vm.provision "shell", inline: "cp /installers/api.chef-server.dev.rb /etc/opscode/chef-server.rb"
    end

    # We do a number of things that can affect the initial configuration - by
    # running reconfigure here we can ensure that they're all completed
    # first  -- no matter what kind of pre-reconfigure provisioning we doing.
    config.vm.provision "shell", inline: "chef-server-ctl reconfigure"

    if plugin_active?('chef-manage', attributes)
      config.vm.provision "shell", "inline": install_hack(m_installer, 'chef-manage')
      config.vm.provision "shell", "inline": "chef-manage-ctl reconfigure --accept-license"
    end

    if plugin_active?('push-jobs-server', attributes)
      backend_compat_message('push-jobs-server') if chef_backend_active?(attributes)
      config.vm.provision "shell", "inline": install_hack(ps_installer, 'opscode-push-jobs-server')
      config.vm.provision "shell", "inline": "opscode-push-jobs-server-ctl reconfigure --accept-license"
    end

    if plugin_active?('reporting', attributes)
      backend_compat_message('reporting') if chef_backend_active?(attributes)
      config.vm.provision "shell", "inline": install_hack(r_installer, 'opscode-reporting')
      config.vm.provision "shell", "inline": "opscode-reporting-ctl reconfigure --accept-license"
    end

  end
end

def define_ldap_server(config, attributes)
  config.vm.hostname = "ldap.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:ldap]
  customize_vm(config, name: "ldap", memory: 512, cpus: 1)

  config.vm.provision "chef_zero" do |chef|
    chef.node_name = config.vm.hostname
    chef.cookbooks_path = "cookbooks"
    chef.add_recipe("provisioning::ldap-server")
    chef.nodes_path = "nodes"
    chef.json = {
      'provisioning' => { 'hosts' =>  ips_to_fqdns },
      'ldap' => {'password' => LDAP_PASSWORD }
    }
  end
end

def define_db_server(config, attributes)
  config.vm.hostname = "database.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:database]
  customize_vm(config, name: "database", memory: 512, cpus: 1)
  set_chef_zero_provisioning(config,
                             recipes: ["provisioning::hosts"],
                             json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
  config.vm.provision "shell", path: "scripts/configure-postgres.sh"
end

def define_custom_server(config, attributes)
  config.vm.hostname = "custom.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:custom]
  customize_vm(config, name: "custom", memory: 2048, cpus: 2)
  set_chef_zero_provisioning(config,
                             recipes: ["provisioning::hosts"],
                             json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
end

def define_elasticsearch_server(config, attributes)
  config.vm.hostname = "elasticsearch.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:elasticsearch]
  customize_vm(config, name: "elasticsearch", memory: 2048, cpus: 2)
  set_chef_zero_provisioning(config,
                             recipes: ["provisioning::hosts"],
                             json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
  config.vm.provision "shell",
                      path: "scripts/provision-elasticsearch.sh",
                      env: { 'ELASTIC_VERSION' => attributes["vm"]["elasticsearch"]["version"] }
end

def define_external_solr_server(config, attributes)
  config.vm.hostname = "solr.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:solr]
  customize_vm(config, name: "external_solr", memory: 2048, cpus: 2)
  set_chef_zero_provisioning(config,
                             recipes: ["provisioning::hosts"],
                             json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
  config.vm.provision "shell", path: "scripts/provision-solr.sh"
  config.vm.provision "file", source: "../omnibus/files/private-chef-cookbooks/private-chef/files/default/solr4/schema.xml", destination: "/home/vagrant/solr-4.10.4/example/solr/collection1/conf/schema.xml"
  config.vm.provision "file", source: "../omnibus/files/private-chef-cookbooks/private-chef/files/default/solr4/solr.xml", destination: "/home/vagrant/solr-4.10.4/example/solr/solr.xml"
  config.vm.provision "shell", path: "scripts/restart-solr.sh"
  
end

def define_backend_server(config, attribute)
  provisioning, installer, installer_path = prepare('BE_INSTALLER', 'chef-backend', 'Chef Backend 1.1+')
  config.vm.hostname = "backend.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:be]
  customize_vm(config, name: "backend", memory: 2048, cpus: 2)
  if provisioning
    config.vm.synced_folder installer_path, "/installers"
    set_chef_zero_provisioning(config,
                               recipes: ["provisioning::hosts"],
                               json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
    config.vm.provision "file", source: "~/.gitconfig", destination: ".gitconfig"
    config.vm.provision "shell", inline: install_hack(installer)
    config.vm.provision "shell", path: "scripts/provision-backend.sh"
  end
end


def define_db_server_reporting(config, attributes)
  config.vm.hostname = "reportingdb.chef-server.dev"
  config.vm.network "private_network", ip: IPS[:reportingdb]
  customize_vm(config, name: "reportingdb", memory: 512, cpus: 1)
  set_chef_zero_provisioning(config,
                             recipes: ["provisioning::hosts"],
                             json: { 'provisioning' => { 'hosts' =>  ips_to_fqdns } })
  # Using shell here to ave the trouble of downloading
  # chef-client for the node.  May reconsider...
  config.vm.provision "shell", inline: configure_postgres
end


##############
# Internals
##############
# These functions are used for provisioning, and ensuring that the VM has
# what it needs to load up and install chef-server
##############


def prepare(installer_env, package_name, title)
  action = ARGV[0]
  if action =~ /^(provision|up|reload)$/
    installer = prompt_installer(installer_env, package_name)
    raise "Please set #{installer_env} to the path of a .deb package for #{title}." if installer.nil?
    raise "#{installer} does not exist! Please fix this." unless File.file?(installer)
    installer_path = File.dirname(File.expand_path(installer))
    provisioning = true
  end
  [provisioning, installer, installer_path]
end

def prompt_installer(installer_env, package_name)
  puts "Package search path: #{Dir.home}/Downloads:#{base_path}/omnibus/pkg"
  # TODO allow config override of location, multiple locations, search pattern, max count?
  files = Dir.glob("#{Dir.home}/Downloads/#{package_name}*.deb") + Dir.glob("#{base_path}/omnibus/pkg/#{package_name}*.deb")

  if ENV[installer_env]
    if ENV[installer_env] =~ /^.*#{package_name}.*deb$/ and File.file?(ENV[installer_env])
      user_installer = File.expand_path(ENV[installer_env])
    else
      puts "#{installer_env} #{ENV[installer_env]} is not a valid #{package_name} package. Ignoring."
    end
  end

  if files.length == 0 and not user_installer
    return nil
  end

  files = files.sort_by{ |f| File.mtime(f) }.last(10)
  files.reverse!
  files << "[#{installer_env}]: #{user_installer}" if user_installer

  selection = 0

  # For the fantastically lazy, allow an environment variable to specify
  # which package selection to use. Special value of '-1' or 'installer' will
  # use the INSTALLER env var automatically (instead of just putting it in
  # the list to choose from).
  if ENV.has_key? 'AUTOPACKAGE'

    selection = ENV['AUTOPACKAGE']
    if (selection == 'installer' or selection == '-1') and user_installer
      # Auto pick the INSTALLER pacckage
      selection = files.length
    else
      selection = selection.to_i
    end

    if selection <= 0 or selection > files.length
      puts "Invalid AUTOPACKAGE selection of #{selection}."
      selection = get_selection(files)
    else
      puts "Using AUTOPACKAGE selection of #{files[selection - 1]}"
    end

  else
    selection = get_selection(installer_env, files)
  end

  if selection == files.length  and user_installer
    user_installer # we munged the text on this one
  else
    files[selection - 1]
  end

end

def get_selection(env, files)
  selection = 0
  files.each_index do |x|
    puts " #{x+1}) #{files[x]}\n"
  end
  loop do
    print "Select an image, or set the #{env} variable and run again: [1 - #{files.length}]: "
    selection = $stdin.gets.chomp.to_i
    break if selection > 0 and selection <= files.length
  end
  selection
end

def host_timezone
  return ENV['DVM_TZ'] if ENV.has_key? 'DVM_TZ'
  require "time"
  # Note that we have to reverse the offset sign if we're using Etc/GMT,
  # reference: http://en.wikipedia.org/wiki/Tz_database#Area
  #  offset = (Time.zone_offset(Time.now.zone) / 3600) * -1
  #  zonesuffix = offset >= 0 ? "+#{offset.to_s}" : "#{offset.to_s}"
  #  "Etc/GMT#{zonesuffix}"
  #  Sigh - sqitch doesn't like the above format and dies.
  if /darwin/ =~ RUBY_PLATFORM
    host_timezone_osx
  else # TODO windows if we otherwise check out for windows.
    host_timezone_linux
  end
end

def host_timezone_linux
  if File.exists?("/etc/timezone")
    File.read("/etc/timezone").chomp
  else
    "UTC"
  end
end

def host_timezone_osx
  if File.exists?(".cached_tz")
    puts "Reading timezone from cache(.cached_tz)"
    File.read(".cached_tz")
  else
    puts "Notice: using sudo to get timezone, no updates being made"
    puts "Executing: sudo systemsetup -gettimezone"
    # Time Zone: Blah/Blah
    tz = `sudo systemsetup -gettimezone`.chomp.split(":")[1].strip
    File.write(".cached_tz", tz)
    tz
  end
end



# this is here in order to avoid having to download a chef provisioner -
# we already have a chef-client install included with the server package, and since
# we're going to run in solo mode, it will run for VM provisioning without
# interfering with the server install.
def install_hack(installer, omnibus = "opscode")
  server_installer_name = File.basename(installer)
  return ";" if server_installer_name.nil?
  <<SCRIPT
cp /home/vagrant/.gitconfig /root/.gitconfig
if [ -d "/opt/#{omnibus}/embedded" ]
then
  echo "Bypassing server install, it appears done."
else
  sudo dpkg -i "/installers/#{server_installer_name}"
fi
SCRIPT
end

def ips_to_fqdns
  final = []
  IPS.map do |shortname, ip|
    next if shortname == :cs  # this is handled in-template provisioning/templates/hosts.erb
    final << "#{ip} #{shortname}.chef-server.dev #{shortname}"
  end
  final
end

def backend_compat_message(plugin)
  puts ""
  puts "WARNING: #{plugin} may not work with Chef Backend"
  puts ""
end

def chef_backend_active?(attributes)
  attributes['vm']['chef-backend']['start']
end

def plugin_active?(plugin, attributes)
  attributes['vm']['plugins'][plugin]
end

def base_path
  File.absolute_path(File.join(Dir.pwd, "../"))
end

def show_autoload_banner(autoload)
  if autoload.length > 0
    puts " *** "
    puts " * The following omnibus components will be loaded prior to reconfigure: "
    autoload.each { |a| puts "   > #{a}" }
    puts " *** "
    puts " "
  end
end

def set_chef_zero_provisioning(config, opts)
  config.vm.provision "chef_zero" do |chef|
    chef.node_name = config.vm.hostname
    chef.cookbooks_path = "cookbooks"
    chef.nodes_path = "nodes"
    chef.binary_path = opts[:chef_path] if opts.has_key?(:chef_path)
    opts[:recipes].each { |recipe| chef.add_recipe(recipe) }
    chef.json = opts[:json]
  end
end

def customize_vm(config, opts)
  config.vm.provider :virtualbox do |vb|
    vb.customize ["modifyvm", :id,
                  "--name", opts[:name],
                  "--memory", opts[:memory] || 512,
                  "--cpus", opts[:cpus] || 2,
                  "--usb", "off",
                  "--usbehci", "off"]
    vb.customize ["storagectl", :id, "--name", "SATA Controller", "--hostiocache", "on"]
  end
end


